{
  "evaluation_timestamp": "2025-10-06T11:04:11.087090",
  "predictions_file": "mining_misconceptions/test_results/openai_o3-mini_effort-medium/single/predictions.json",
  "misconceptions_file": "mining_misconceptions/data/misconception.json",
  "prediction_format": "single-code",
  "claude_evaluation_used": true,
  "recall_metrics": {
    "recall": 0.3880597014925373,
    "total_true_misconceptions": 67,
    "total_found_misconceptions": 26,
    "similarity_threshold": 0.5,
    "total_predictions_analyzed": 1675
  },
  "precision_metrics": {
    "total_unique_predictions": 1050,
    "total_prediction_instances": 1084,
    "awaiting_labels": 1050,
    "labeled": 0
  },
  "claude_evaluation_metrics": {
    "standard": {
      "precision": 0.6392988929889298,
      "recall": 0.4137313432835821,
      "f1_score": 0.5023559260601667,
      "overall_accuracy": 0.4137313432835821,
      "true_positives": 693,
      "false_positives": 391,
      "false_negatives": 982,
      "true_negatives": 0
    },
    "with_novel": {
      "precision": 0.8293357933579336,
      "recall": 0.4779372674109516,
      "f1_score": 0.6064080944350758,
      "overall_accuracy": 0.5367164179104478,
      "true_positives": 899,
      "true_positives_breakdown": {
        "standard": 693,
        "novel": 206
      },
      "false_positives": 185,
      "false_negatives": 982,
      "true_negatives": 0
    },
    "novel_validation_enabled": true
  }
}